language ESSENCE' 1.0

given n: int(0..100)
given a: int(0..100)
given b: int(0..100)
given fin1: int
given s_Occurrence: matrix indexed by [int(1..n)] of bool
find x_ExplicitVarSizeWithDummy:
        matrix indexed by [int(1..1 + (b - a))] of int(a..b + 1)
such that
    and([x_ExplicitVarSizeWithDummy[q6] != b + 1 ->
         s_Occurrence[x_ExplicitVarSizeWithDummy[q6]]
             | q6 : int(1..1 + (b - a))]),
    or([x_ExplicitVarSizeWithDummy[q8] != b + 1 /\
        x_ExplicitVarSizeWithDummy[q8] =
        sum([toInt(x_ExplicitVarSizeWithDummy[q10] != b + 1)
                 | q10 : int(1..1 + (b - a))])
            | q8 : int(1..1 + (b - a))]),
    and([x_ExplicitVarSizeWithDummy[q1] < x_ExplicitVarSizeWithDummy[q1 + 1] \/
         x_ExplicitVarSizeWithDummy[q1] = b + 1
             | q1 : int(1..1 + (b - a) - 1)]),
    and([x_ExplicitVarSizeWithDummy[q2] = b + 1 ->
         x_ExplicitVarSizeWithDummy[q2 + 1] = b + 1
             | q2 : int(1..1 + (b - a) - 1)])

