language ESSENCE' 1.0

given n: int(1..)
letting q1 be n - 1
find s_Function1D: matrix indexed by [int(1..n)] of int(0..q1)
letting q2 be n - 1
letting q3 be n - 1
find v_Function1D: matrix indexed by [int(1..q2)] of int(1..q3)
such that
    and([v_Function1D[i] = |s_Function1D[i + 1] - s_Function1D[i]|
             | i : int(1..n - 1)]),
    allDiff(v_Function1D),
    and([or([v_Function1D[q5] = q4 | q5 : int(1..q2)]) | q4 : int(1..q3)]),
    allDiff(s_Function1D),
    and([or([s_Function1D[q7] = q6 | q7 : int(1..n)]) | q6 : int(0..q1)])

